{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C)Mostafa Amin-Naji, Babol Noshirvani University of Technology,\n",
    "# My Official Website: www.Amin-Naji.com\n",
    "# My Email: Mostafa.Amin.Naji@Gmail.com\n",
    "\n",
    "# PLEASE CITE THE BELOW PAPER IF YOU USE THIS CODE\n",
    "\n",
    "# M. Amin-Naji, A. Aghagolzadeh, and M. Ezoji, “Ensemble of CNN for Multi-Focus Image Fusion”, Information Fusion, vol. 51, pp. 21–214, 2019. \n",
    "# DOI: https://doi.org/10.1016/j.inffus.2019.02.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import PIL.ImageOps \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from train import train_model\n",
    "# from model_utils import *\n",
    "# from predict_utils import *\n",
    "# from vis_utils import *\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"C:/Users/Aghagolzadeh_PC/Desktop/mostafa/focus&unfocus5/\"\n",
    "trn_dir = f'{DATA_DIR}/train'\n",
    "tst_dir = f'{DATA_DIR}/test'\n",
    "\n",
    "sz = 32\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = [f for f in glob(f'{trn_dir}/*/*.jpg')]   # training images\n",
    " \n",
    "\n",
    "# num_images = len(images)\n",
    "# avg_width, avg_height = 0.0, 0.0\n",
    "# for img_fname in tqdm(images, desc='Gathering statistics'):\n",
    "#     w, h = Image.open(img_fname).size\n",
    "#     avg_width += w\n",
    "#     avg_height += h\n",
    "    \n",
    "# avg_width /= num_images\n",
    "# avg_height /= num_images\n",
    "\n",
    "# print('Average width: {:.2f}, Average height: {:.2f}'.format(avg_width, avg_height))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.array([0., 0., 0.])\n",
    "# std = np.array([0., 0., 0.])\n",
    "\n",
    "# for img_fname in tqdm(images, desc='Gathering statistics'):\n",
    "#     img = np.array(Image.open(img_fname).convert('RGB'))\n",
    "#     mean += np.mean(img, axis=(0, 1))\n",
    "#     std += np.std(img, axis=(0, 1))\n",
    "\n",
    "# mean /= num_images\n",
    "# std /= num_images\n",
    "\n",
    "# print('Mean:', mean / 255.0)\n",
    "# print('Std:', std / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_fnames = glob(f'{trn_dir}/*/*.jpg')\n",
    "trn_fnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(trn_fnames[100])\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.ImageFolder(trn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([\n",
    "    transforms.Resize((sz, sz//2)),  # PIL Image\n",
    "#     transforms.Grayscale(), \n",
    "    transforms.ToTensor(),        # Tensor\n",
    "    transforms.Normalize([0.44 , 0.053, 0.062], [0.076, 0.079, 0.085])\n",
    "#     transforms.Normalize(mean=(0.485,), std=(0.229,))\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(trn_dir, transform=tfms)\n",
    "test_ds = datasets.ImageFolder(tst_dir, transform=tfms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, \n",
    "                                       shuffle=True, num_workers=8)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, \n",
    "                                       shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(train_dl))\n",
    "out = torchvision.utils.make_grid(inputs, padding=3)\n",
    "plt.figure(figsize=(16, 12))\n",
    "imshow(out, title='Random images from training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = nn.Softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        self.conv1_2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        self.conv1_3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.conv2_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2_3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv3_1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )   \n",
    "        self.conv3_2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )   \n",
    "        \n",
    "        self.conv3_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )   \n",
    "    \n",
    "        \n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128*2, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )   \n",
    "\n",
    "        self.fc1 = nn.Linear(256*8*4*2, 2)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, y, z):\n",
    "        outx = self.conv1_1(x)\n",
    "        outx = self.conv2_2(outx)\n",
    "        outx = self.conv3_1(outx)\n",
    "        outx = self.conv4(outx)\n",
    "        outx = outx.view(outx.size(0), -1)\n",
    "        \n",
    "        outy = self.conv1_2(y)\n",
    "        outy = self.conv2_2(outy)\n",
    "        outy = self.conv3_2(outy)\n",
    "\n",
    "        \n",
    "        outz = self.conv1_3(z)\n",
    "        outz = self.conv2_3(outz)\n",
    "        outz = self.conv3_3(outz)\n",
    "        \n",
    "        oyz=torch.cat([outy,outz],1)\n",
    "        \n",
    "        oyz = self.conv5(oyz)\n",
    "        oyz = oyz.view(oyz.size(0), -1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        oo=torch.cat([outx,oyz],1)\n",
    "        \n",
    "\n",
    "        \n",
    "        out = self.fc1(oo)\n",
    "        \n",
    "       \n",
    "\n",
    "   \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "if use_gpu:\n",
    "\n",
    "    \n",
    "    model = model.cuda()\n",
    "    model.cuda()\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0002, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, volatile=volatile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = time.time()\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        \n",
    "\n",
    "        \n",
    "        inputs = to_var(inputs)\n",
    "#         inputs2 = to_var(inputs2)\n",
    "#         inputs3 = to_var(inputs3)\n",
    "        targets = to_var(targets)\n",
    "        \n",
    "        inputs1=inputs[:,0,:,:]\n",
    "        inputs1=inputs1.resize(inputs1.shape[0],1,32,16)\n",
    "        inputs2=inputs[:,1,:,:]\n",
    "        inputs2=inputs1.resize(inputs2.shape[0],1,32,16)\n",
    "        inputs3=inputs[:,2,:,:]\n",
    "        inputs3=inputs1.resize(inputs3.shape[0],1,32,16)\n",
    "        \n",
    "        # forwad pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs1,inputs2,inputs3)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        losses += [loss.data[0]]\n",
    "\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # report\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print('Epoch [%2d/%2d], Step [%3d/%3d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(train_ds) // batch_size, loss.data[0]))\n",
    "            \n",
    "b = time.time()\n",
    "print('Total Time of Training {:.1000}s'.format(b - a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Cross Entropy Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # for batch normalization layers\n",
    "    corrects = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = to_var(inputs, True), to_var(targets, True)\n",
    "#         targets = to_var(targets)\n",
    "        \n",
    "        inputs1=inputs[:,0,:,:]\n",
    "        inputs1=inputs1.resize(inputs1.shape[0],1,32,16)\n",
    "        inputs2=inputs[:,1,:,:]\n",
    "        inputs2=inputs1.resize(inputs2.shape[0],1,32,16)\n",
    "        inputs3=inputs[:,2,:,:]\n",
    "        inputs3=inputs1.resize(inputs3.shape[0],1,32,16)\n",
    "        \n",
    "        outputs = model(inputs1,inputs2,inputs3)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        corrects += (preds == targets.data).sum()\n",
    "        \n",
    "    zz=len(dataloader.dataset)\n",
    "    \n",
    "    print('accuracy: {:.2f}'.format(100. * corrects / len(dataloader.dataset)))\n",
    "    print('corrects: {:.2f}'.format(corrects))\n",
    "    print('Toatal: {:.2f}'.format(zz))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ECNN_network_wights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
