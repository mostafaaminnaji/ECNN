{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C)Mostafa Amin-Naji, Babol Noshirvani University of Technology,\n",
    "# My Official Website: www.Amin-Naji.com\n",
    "# My Email: Mostafa.Amin.Naji@Gmail.com\n",
    "\n",
    "# PLEASE CITE THE BELOW PAPER IF YOU USE THIS CODE\n",
    "\n",
    "# M. Amin-Naji, A. Aghagolzadeh, and M. Ezoji, “Ensemble of CNN for Multi-Focus Image Fusion”, Information Fusion, vol. 51, pp. 21–214, 2019. \n",
    "# DOI: https://doi.org/10.1016/j.inffus.2019.02.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as numpy\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        self.conv1_2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        self.conv1_3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.conv2_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2_3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv3_1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )   \n",
    "        self.conv3_2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )   \n",
    "        \n",
    "        self.conv3_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )   \n",
    "    \n",
    "        \n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128*2, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )   \n",
    "\n",
    "        self.fc1 = nn.Linear(256*8*4*2, 2)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, y, z):\n",
    "        outx = self.conv1_1(x)\n",
    "        outx = self.conv2_2(outx)\n",
    "        outx = self.conv3_1(outx)\n",
    "        outx = self.conv4(outx)\n",
    "        outx = outx.view(outx.size(0), -1)\n",
    "        \n",
    "        outy = self.conv1_2(y)\n",
    "        outy = self.conv2_2(outy)\n",
    "        outy = self.conv3_2(outy)\n",
    "\n",
    "        \n",
    "        outz = self.conv1_3(z)\n",
    "        outz = self.conv2_3(outz)\n",
    "        outz = self.conv3_3(outz)\n",
    "        \n",
    "        oyz=torch.cat([outy,outz],1)\n",
    "        \n",
    "        oyz = self.conv5(oyz)\n",
    "        oyz = oyz.view(oyz.size(0), -1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        oo=torch.cat([outx,oyz],1)\n",
    "        \n",
    "\n",
    "        \n",
    "        out = self.fc1(oo)\n",
    "        \n",
    "       \n",
    "\n",
    "   \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='ECNN_trained_network_wights.pth'\n",
    "\n",
    "use_gpu=torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "\n",
    "    print('GPU Mode Acitavted')\n",
    "    model = model.cuda()\n",
    "    model.cuda()\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('CPU Mode Acitavted')\n",
    "    state_dict = torch.load(model_path,map_location='cpu')\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_path1= './lytro-03-A.jpg'  \n",
    "original_path2= './lytro-03-B.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "\n",
    "windows_size=32\n",
    "# it can be set as 2 or 4 based on the size of input images, stride=2 is more accurate but stride=4 is more faster\n",
    "stride = 2  \n",
    "\n",
    "\n",
    "tfms1 = transforms.Compose([\n",
    "    transforms.Resize((64, 32)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.45 ], [0.1])\n",
    "])\n",
    "\n",
    "tfms2 = transforms.Compose([\n",
    "    transforms.Resize((64, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([ 0.050], [ 0.09])\n",
    "])\n",
    "tfms3 = transforms.Compose([\n",
    "    transforms.Resize((64, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.06], [ 0.09])\n",
    "])\n",
    "\n",
    "\n",
    "img1 = Image.open(original_path1)\n",
    "img2 = Image.open(original_path2)\n",
    "\n",
    "img1 = np.asarray(img1)\n",
    "img2 = np.asarray(img2)\n",
    "\n",
    "kernel=np.array([[-1 ,   -2 ,   -1],  [0 ,    0    , 0],  [1 ,    2,     1]])\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img1_GY = cv2.filter2D(img1_gray,-1,kernel)\n",
    "img1_GX = cv2.filter2D(img1_gray,-1,np.transpose(kernel))\n",
    "\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "img2_GY = cv2.filter2D(img2_gray,-1,kernel)\n",
    "img2_GX = cv2.filter2D(img2_gray,-1,np.transpose(kernel))\n",
    "\n",
    "\n",
    "# test_image1 = cv2.resize(test_image1, (test_image1.shape[1]*1, test_image1.shape[0]*1)) \n",
    "# test_image2 = cv2.resize(test_image2, (test_image2.shape[1]*1, test_image2.shape[0]*1))\n",
    "\n",
    "test_image1_1=img1_gray\n",
    "test_image1_2=img1_GX\n",
    "test_image1_3=img1_GY\n",
    "\n",
    "test_image2_1=img2_gray\n",
    "test_image2_2=img2_GX\n",
    "test_image2_3=img2_GY\n",
    "\n",
    "\n",
    "source1=img1\n",
    "source2=img2\n",
    "\n",
    "\n",
    "j=0\n",
    "\n",
    "map1=np.zeros([img1.shape[0], img1.shape[1]])\n",
    "map2=np.zeros([img1.shape[0], img1.shape[1]])\n",
    "map3=np.zeros([img1.shape[0], img1.shape[1]])\n",
    "map4=map3\n",
    "MAP=np.zeros([img1.shape[0], img1.shape[1]])\n",
    "\n",
    "score1=0\n",
    "score2=0\n",
    "FUSED=np.zeros(test_image1_1.shape)\n",
    "\n",
    "windowsize_r = windows_size-1\n",
    "windowsize_c = windows_size-1\n",
    "\n",
    "for r in tqdm(range(0,img1.shape[0] - windowsize_r, stride)):\n",
    "    for c in range(0,img1.shape[1] - windowsize_c, stride):\n",
    "        \n",
    "        block_test1_1 = test_image1_1[r:r+windowsize_r+1,c:c+windowsize_c+1]\n",
    "        block_test1_2 = test_image1_2[r:r+windowsize_r+1,c:c+windowsize_c+1]\n",
    "        block_test1_3 = test_image1_3[r:r+windowsize_r+1,c:c+windowsize_c+1]\n",
    "        \n",
    "        block_test2_1 = test_image2_1[r:r+windowsize_r+1,c:c+windowsize_c+1]\n",
    "        block_test2_2 = test_image2_2[r:r+windowsize_r+1,c:c+windowsize_c+1]\n",
    "        block_test2_3 = test_image2_3[r:r+windowsize_r+1,c:c+windowsize_c+1]\n",
    " \n",
    "        block1_1= np.concatenate((block_test1_1, block_test2_1), axis=0)\n",
    "        block2_1= np.concatenate((block_test2_1, block_test1_1), axis=0)  \n",
    "        block1_1 = Image.fromarray(block1_1, 'L')\n",
    "        block2_1 = Image.fromarray(block2_1, 'L')\n",
    "        block1_2= np.concatenate((block_test1_2, block_test2_2), axis=0)\n",
    "        block2_2= np.concatenate((block_test2_2, block_test1_2), axis=0)  \n",
    "        block1_2 = Image.fromarray(block1_2, 'L')\n",
    "        block2_2 = Image.fromarray(block2_2, 'L')\n",
    "        block1_3= np.concatenate((block_test1_3, block_test2_3), axis=0)\n",
    "        block2_3= np.concatenate((block_test2_3, block_test1_3), axis=0)  \n",
    "        block1_3 = Image.fromarray(block1_3, 'L')\n",
    "        block2_3 = Image.fromarray(block2_3, 'L')\n",
    "                 \n",
    "        imout1_1=tfms1(block1_1)\n",
    "        imout2_1=tfms1(block2_1)\n",
    "        imout1_2=tfms2(block1_2)\n",
    "        imout2_2=tfms2(block2_2)\n",
    "        imout1_3=tfms3(block1_3)\n",
    "        imout2_3=tfms3(block2_3)\n",
    "        \n",
    "        if use_gpu:\n",
    "            imout1_1=to_var(imout1_1)\n",
    "            imout2_1=to_var(imout2_1)\n",
    "            imout1_2=to_var(imout1_2)\n",
    "            imout2_2=to_var(imout2_2)\n",
    "            imout1_3=to_var(imout1_3)\n",
    "            imout2_3=to_var(imout2_3)\n",
    "        \n",
    "        imout1_1=(imout1_1)\n",
    "        imout2_1=(imout2_1)\n",
    "        imout1_2=(imout1_2)\n",
    "        imout2_2=(imout2_2)\n",
    "        imout1_3=(imout1_3)\n",
    "        imout2_3=(imout2_3)\n",
    "        \n",
    "        \n",
    "        inputs1_1 = imout1_1.unsqueeze(0)\n",
    "        inputs2_1 = imout2_1.unsqueeze(0)\n",
    "        inputs1_2 = imout1_2.unsqueeze(0)\n",
    "        inputs2_2 = imout2_2.unsqueeze(0)\n",
    "        inputs1_3 = imout1_3.unsqueeze(0)\n",
    "        inputs2_3 = imout2_3.unsqueeze(0)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        outputs1 = model(inputs1_1,inputs1_2,inputs1_3)\n",
    "        _, predicted1 = torch.max(outputs1.data, 1)\n",
    "        \n",
    "        score1=predicted1.detach().cpu().numpy()\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        outputs2 = model(inputs2_1,inputs2_2,inputs2_3)\n",
    "        _, predicted2 = torch.max(outputs2.data, 1)\n",
    "        \n",
    "        score2=predicted2.detach().cpu().numpy()\n",
    "        \n",
    "        map2[r:r+windowsize_r+1,c:c+windowsize_c+1] += 1\n",
    "        \n",
    "        if score1 <= score2:\n",
    "            map1[r:r+windowsize_r+1,c:c+windowsize_c+1] += +1 \n",
    "      \n",
    "        else:\n",
    "            map1[r:r+windowsize_r+1,c:c+windowsize_c+1] += -1 \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(map1, cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map11=map1\n",
    "img1 = imageio.imread(original_path1)\n",
    "img2 = imageio.imread(original_path2)\n",
    "\n",
    "test_image1 = np.asarray(img1)\n",
    "test_image2 = np.asarray(img2)\n",
    "\n",

    "\n",
    "FUSED=np.zeros(img1.shape)\n",
    "for r in range(0,img1.shape[0], 1):\n",
    "    for c in range(0,img1.shape[1], 1):   \n",
    "        \n",
    "        if map11[r,c] < 0:\n",
    "            map3[r,c] =0\n",
    "            FUSED[r,c]=img2[r,c]\n",
    "            \n",
    "        else:\n",
    "            map3[r,c] =1\n",
    "            FUSED[r,c]=img1[r,c]\n",
    "            \n",
    "FUSED_8=FUSED.astype(np.uint8)\n",
    "# imageio.imwrite('./output.tif', FUSED_8)\n",
    "# imageio.imwrite('./output.jpg', FUSED_8)\n",
    "plt.imshow(map3, cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(FUSED_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=test_image1.shape[0]//20\n",
    "# z=test_image1.shape[1]//20\n",
    "# kernel = np.ones((x,z),np.float32)/(x*z)\n",
    "# MAP2 = cv2.filter2D(map1,-1,kernel)\n",
    "# MAP2[MAP2<0.5] = 0\n",
    "# MAP2[MAP2>=0.5] = 1\n",
    "\n",
    "# FUSED_CV=np.zeros(img1.shape)\n",
    "\n",
    "# FUSED=np.zeros(img1.shape)\n",
    "# for r in range(0,img1.shape[0], 1):\n",
    "#     for c in range(0,img1.shape[1], 1):   \n",
    "        \n",
    "#         if MAP2[r,c] < 0.5:\n",
    "            \n",
    "#             FUSED_CV[r,c]=img1[r,c]\n",
    "            \n",
    "#         else:\n",
    "            \n",
    "#             FUSED_CV[r,c]=img2[r,c]\n",
    "\n",
    "\n",
    "# FUSED_CV=FUSED_CV.astype(np.uint8)\n",
    "# imageio.imwrite('./output_CV.tif', FUSED_CV)\n",
    "# imageio.imwrite('./output_CV.jpg', FUSED_CV)\n",
    "\n",
    "# plt.imshow(MAP2, cm.gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
